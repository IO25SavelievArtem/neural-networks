{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":840806,"sourceType":"datasetVersion","datasetId":59760}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#1. Завантажуємо датасет для роботи\n# Встановлюємо keggle\n! pip install kaggle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Монтуємо Google Drive\nfrom google.colab import drive\ndrive.mount(\"/content/drive\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-06T14:21:37.155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Робимо папку та копіюємо в неї файл з API key\n! mkdir ~/.kaggle\n! cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json\n# Обмежуємо доступ до файлу\n! chmod 600 ~/.kaggle/kaggle.json\n# Завантажуємо датасет\n! kaggle datasets download alessiocorrado99/animals10\n# Розпаковуємо архів\n! unzip animals10.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T14:20:50.016905Z","iopub.status.idle":"2025-11-06T14:20:50.017527Z","shell.execute_reply.started":"2025-11-06T14:20:50.017283Z","shell.execute_reply":"2025-11-06T14:20:50.017310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#2. Розділяємо дані на навчальні та тестові\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimg_size = (227, 227)\nbatch_size = 32\nextract_path=\"/content/raw-img\"\ndatagen = ImageDataGenerator(\n    rescale=1.0/255, # Нормалізація\n    validation_split=0.2 # 20% даних під валідацію\n)\ntrain_generator = datagen.flow_from_directory(\n    extract_path,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\nval_generator = datagen.flow_from_directory(\n    extract_path,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n#3. Створюємо шари нейромережі\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nmodel = Sequential([\n    Input(shape=(227, 227, 3)),\n    Conv2D(96, (11, 11), strides=4, activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((3, 3), strides=2),\n    Conv2D(256, (5, 5), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D((3, 3), strides=2),\n    Conv2D(384, (3, 3), activation='relu', padding='same'),\n    Conv2D(384, (3, 3), activation='relu', padding='same'),\n    Conv2D(256, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D((3, 3), strides=2),\n    Flatten(),\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    Dense(10, activation='softmax') # 10 класів\n])\n\nfrom tensorflow.keras.optimizers import Adam\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[ 'accuracy'])\nprint(model.summary())\n\n#4. Навчаємо модель\nhistory = model.fit(\n    train_generator,\n    epochs=30,\n    validation_data=val_generator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T14:20:50.019086Z","iopub.status.idle":"2025-11-06T14:20:50.019559Z","shell.execute_reply.started":"2025-11-06T14:20:50.019307Z","shell.execute_reply":"2025-11-06T14:20:50.019327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#5. Виводимо точність та втрати\nloss, accuracy = model.evaluate(val_generator)\nprint(f\"Точність на валідації: {accuracy:.4f}\")\nprint(f\"Втрати (Loss): {loss:.4f}\")\n\n#6. Будуємо графіки точності та втрати\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Точність на тренуванні')\nplt.plot(epochs_range, val_acc, label='Точність на валідації')\nplt.legend()\nplt.title('Графік точності')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Втрати на тренуванні')\nplt.plot(epochs_range, val_loss, label='Втрати на валідації')\nplt.legend()\nplt.title('Графік втрат')\nplt.show()\n\n#7. Перевіряємо розпізнавання на випадковому зображенні\nimport numpy as np\nimport random\nimport os\nfrom tensorflow.keras.preprocessing import image\nclass_names = list(train_generator.class_indices.keys())\nrandom_class = random.choice(class_names)\nrandom_image_path = random.choice(os.listdir(f\"{extract_path}/{random_class}\"))\nimg_path = f\"{extract_path}/{random_class}/{random_image_path}\"\nimg = image.load_img(img_path, target_size=(227, 227))\nimg_array = image.img_to_array(img) / 255.0\nimg_array = np.expand_dims(img_array, axis=0)\npredictions = model.predict(img_array)\nprint(predictions)\npredicted_class = class_names[np.argmax(predictions)]\nplt.imshow(img)\nplt.axis('off') \nplt.title(f\"Очікуваний: {random_class}\\nПередбачений: {predicted_class}\")\nplt.show()\n\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.preprocessing import image\nnum_images = 1024\nbatch_size = 128\noutput_csv = \"classification_results.csv\"\nall_images = []\nfor class_name in os.listdir(extract_path):\n    class_dir = os.path.join(extract_path, class_name)\n    if os.path.isdir(class_dir):\n        for img_name in os.listdir(class_dir):\n            img_path = os.path.join(class_dir, img_name)\n            all_images.append((img_path, class_name))\nselected_images = random.sample(all_images, num_images)\ndef load_batch(image_data):\n    images = []\n    paths = []\n    true_classes = []\n    for img_path, true_class in image_data:\n        img = image.load_img(img_path, target_size=(227, 227))\n        img_array = image.img_to_array(img) / 255.0\n        images.append(img_array)\n        paths.append(img_path)\n        true_classes.append(true_class)\n    return np.array(images), paths, true_classes\n\nresults = []\nfor i in range(0, num_images, batch_size):\n    batch_data = selected_images[i:i+batch_size]\n    batch_images, batch_paths, batch_true_classes = load_batch(batch_data)\n    predictions = model.predict(batch_images)\n    predicted_classes = np.argmax(predictions, axis=1)\n    for j in range(len(batch_paths)):\n        results.append([batch_paths[j], batch_true_classes[j], class_names[pr edicted_classes[j]]])\n\ndf = pd.DataFrame(results, columns=[\"Шлях до файлу\", \"Справжній клас\", \"Розпі знаний клас\"])\ndf.to_csv(output_csv, index=False, encoding=\"utf-8\")\nprint(f\"Результати збережені у {output_csv}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T14:20:50.022464Z","iopub.status.idle":"2025-11-06T14:20:50.023325Z","shell.execute_reply.started":"2025-11-06T14:20:50.022870Z","shell.execute_reply":"2025-11-06T14:20:50.022906Z"}},"outputs":[],"execution_count":null}]}